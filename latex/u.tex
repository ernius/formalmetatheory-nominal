\documentclass{entcs} 
\usepackage{entcsmacro}
\usepackage{graphicx}
\sloppy
% The following is enclosed to allow easy detection of differences in
% ascii coding.
% Upper-case    A B C D E F G H I J K L M N O P Q R S T U V W X Y Z
% Lower-case    a b c d e f g h i j k l m n o p q r s t u v w x y z
% Digits        0 1 2 3 4 5 6 7 8 9
% Exclamation   !           Double quote "          Hash (number) #
% Dollar        $           Percent      %          Ampersand     &
% Acute accent  '           Left paren   (          Right paren   )
% Asterisk      *           Plus         +          Comma         ,
% Minus         -           Point        .          Solidus       /
% Colon         :           Semicolon    ;          Less than     <
% Equals        =3D           Greater than >          QuestIon mark ?
% At            @           Left bracket [          Backslash     \
% Right bracket ]           Circumflex   ^          Underscore    _
% Grave accent  `           Left brace   {          Vertical bar  |
% Right brace   }           Tilde        ~

%   \documentclass{article}

    % When using XeLaTeX, the following should be used instead:
    % \documentclass[xetex, mathserif, serif]{beamer}
    %
    % The default font in XeLaTeX doesn’t have the default bullet character, so 
    % either change the font:
    % \setmainfont{XITS}
    % \setmathfont{XITS Math}
    %
    % Or change the character:
    %\setbeamertemplate{itemize items}{•}

%\usepackage[bw,references]{latex/agda}
%\usepackage[conor,references]{latex/agda}
%\usepackage[hidelinks]{hyperref}
\usepackage[references,links]{agda}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{textgreek}
\usepackage{catchfilebetweentags}
\usepackage{tipa}

%math
\newcommand{\alp}{\ensuremath{\alpha}}
\newcommand{\lamb}{\ensuremath{\lambda}}
\newcommand{\alphaeqsym}{\ensuremath{\sim_\alpha}}
\newcommand{\choice}{\ensuremath{\chi}}

%Agda
\newcommand{\freshin}[2]{\ensuremath{#1 \mathbin{\AgdaDatatype{\#}} #2}}
\newcommand{\lambAg}[2]{\ensuremath{\AgdaInductiveConstructor{ƛ}\, #1\, #2}}
\newcommand{\inAg}{\ensuremath{\mathbin{\AgdaFunction{∈}}}}
\newcommand{\ninAg}{\ensuremath{\mathbin{\AgdaFunction{∉}}}}
\newcommand{\neqAg}{\ensuremath{\mathbin{\AgdaInductiveConstructor{≢}}}}
\newcommand{\ap}[2]{#1 \ensuremath{\mathbin{\AgdaInductiveConstructorFunction{·}} #2}}
\newcommand{\var}[1]{\ensuremath{\AgdaInductiveConstructorFunction{v}\, #1}}
\newcommand{\fv}{\ensuremath{{\AgdaFunction{fv}}\,}}
\newcommand{\perm}{\ensuremath{\mathbin{\AgdaFunction{∙}}}}
\newcommand{\free}{\ensuremath{\mathbin{\AgdaFunction{*}}}}
\newcommand{\choiceAg}{\ensuremath{\AgdaFunction{χ}\,}}
\newcommand{\choiceAgaux}{\ensuremath{\AgdaFunction{χ'}\,}}
\newcommand{\alpeqAg}{\ensuremath{\mathbin{\AgdaDatatype{∼α}}}}
\newcommand{\swap}[3]{\ensuremath{(#1 \mathbin{\AgdaFunction{∙}} #2)\, #3}}

% \newcommand{\agdaf}[1]{\ensuremath{\AgdaFunction{#1}\,}}
% \newcommand{\agdaD}[1]{\ensuremath{\AgdaDatatype{#1}\,}}
% \newcommand{\agdav}[1]{\ensuremath{\AgdaBound{#1}\,}}

\DeclareUnicodeCharacter{411}{\textipa{\textcrlambda}}
\DeclareUnicodeCharacter{65288}{(}
\DeclareUnicodeCharacter{65289}{)}
\DeclareUnicodeCharacter{8788}{\ensuremath{\coloneqq}}
\DeclareUnicodeCharacter{8336}{\ensuremath{_a}}
\DeclareUnicodeCharacter{8799}{\ensuremath{\overset{?}{=}}}
\DeclareUnicodeCharacter{8759}{\ensuremath{\dblcolon}}
\DeclareUnicodeCharacter{8718}{\ensuremath{\square}}

%\title{Formalisation in Constructive Type Theory of Alpha-Structural Induction and Recursion for the Lambda Calculus.}

\def\lastname{Bove,  Fernandez ,  Tasistro , Szasz  and Copello}

\begin{document}

\begin{frontmatter}
 \title{Alpha-Structural Induction and Recursion for the Lambda Calculus in Constructive Type Theory}
  \author{Ana Bove \thanksref{emailB}}
  \address{Chalmers University of Technology\\
    Gothenburg, Sweden}
  \author{Maribel Fernandez \thanksref{emailF}}
  \address{King's College London\\
      London, England}
  \author{\'Alvaro Tasistro \thanksref{emailT}}
  \author{Nora Szasz \thanksref{emailS}}
  \author{Ernesto Copello \thanksref{emailC}}
  \address{Universidad ORT Uruguay\\
      Montevideo, Uruguay}
  \thanks[emailB]{Email: \href{mailto:bove@chalmers.se} {\texttt{\normalshape bove@chalmers.se}}}
  \thanks[emailF]{Email: \href{mailto:Maribel.Fernandez@kcl.ac.uk} {\texttt{\normalshape Maribel.Fernandez@kcl.ac.uk}}}
  \thanks[emailT]{Email: \href{mailto:tasistro@ort.edu.uy} {\texttt{\normalshape tasistro@ort.edu.uy}}} 
  \thanks[emailS]{Email: \href{mailto:szasz@ort.edu.uy} {\texttt{\normalshape szasz@ort.edu.uy}}}
  \thanks[emailC]{Email: \href{mailto:copello@ort.edu.uy} {\texttt{\normalshape copello@ort.edu.uy}}}

\begin{abstract} 
We formulate principles of induction and recursion for a variant of lambda calculus with bound names where \alp-conversion is based upon name swapping as in nominal abstract syntax. The principles allow to work modulo alpha-conversion and implement the Barendregt variable convention. We derive them all from the simple structural induction principle on concrete terms and work out applications to some fundamental meta-theoretical results, such as the substitution lemma for alpha-conversion and the lemma on substitution composition. The whole work is implemented in Agda.
\end{abstract}

\begin{keyword}
Formal Metatheory, Lambda Calculus, Constructive Type Theory
\end{keyword}

\end{frontmatter}

\maketitle

\section{Introduction}
\label{sec:intro}
We are interested in methods for formalising in constructive type theory the meta-theory of the lambda-calculus. The main reason for this is that the lambda calculus is both a primigenial programming language and a prime test bed
for formal reasoning on tree structures that feature (name) binding. 

Specifically concerning the latter, the informal procedure consists to begin with in ``identifying terms up to $\alpha$-conversion''. However, this is not simply carried out when functions are defined by recursion and properties proven by induction. The problem has to do with the fact that the consideration of the $\alpha$-equivalence classes is actually conducted through the use of convenient representatives thereof. These are chosen by the so-called Barendregt Variable Convention (BVC): each term representing its $\alpha$-class is chosen so that its bound names are all different and different from all names free in the current context. Now a general validity criterion determines that this procedure ought to be accompanied in all cases by the verification that the proofs and results of functions depend only on the $\alpha$-class and do not vary with the particular choice of the representative in question. Such verification is seldom accomplished but yet it is not the main difficulty concerning the validity of the constructions so performed. The main point is that e.g. inductive proofs are often carried out employing the structural principle for concrete terms ---and then it may well happen that an induction step corresponding to functional abstractions can be carried out for a conveniently chosen bound name but not for an arbitrary one as the principle requires.

The problem can be avoided by the use of de Bruijn's nameless syntax \cite{deBruijn1972} or its more up-to-date version \textit{locally nameless} syntax \cite{aydemir08,chargueraud12}, which uses names for the free or global variables and the indices counting up to the binding abstractor for the occurrences of local parameters. But these methods are not without overhead in the form of  several operations or well-formedness predicates.
As a result, there certainly is a relief in not having to consider $\alpha$-conversion; but, at the same time, the nameless syntax seriously affects the connection between actual terms and their manipulation on the one hand and the informal statements concerning them on the other, so that one can easily get things wrong. 
The same has to be said of the map representation introduced in \cite{sato}.

A different alternative is to replace the (as explained above, problematic) use of structural induction and recursion principles on concrete terms by that of so-called \emph{alpha}-structural principles working directly on the $\alpha$-equivalence classes. This means providing principles that allow to prove properties by induction and defining functions by recursion by direct use of the BVC, somewhat easying the burden associated to the verification of the validity of the procedure.

A first attempt in this direction is ~\cite{DBLP:conf/tphol/GordonM96}, which gives an axiomatic description of lambda terms in which equality embodies $\alpha$-conversion and that provides a method of definition of functions by recursion on such type of objects. This solution ultimately rests upon the use of higher-order abstract syntax within the HOL system, and a theoretical model using de Bruijn's nameless syntax is sketched to show the soundness of the system of axioms.
In \cite{Gabbay, Pitts1, Pitts2}, models of syntax with binders are introduced which formulate the basic concepts of abstraction, $\alpha$-equivalence and a name being ``sufficiently fresh'' in a mathematical object, on the basis of the simple operation of name swapping. This theory ---which has become known as \emph{nominal abstract syntax}--- provides a framework of (first-order) languages with binding with associated principles of $\alpha$-structural recursion and induction that are based on the verification of the non-dependence of the mathematical objects in the current context, as well as of the results of recursively defined functions, on the bound names chosen for the representatives of the $\alpha$-classes involved.
Implementations of this approach have been tried in Isabelle/HOL ~\cite{urban05} and Coq \cite{aydemir}. In the first case the solution rests upon a weak version of higher-order abstract syntax, whereas the second one is an axiomatisation in which ---similarly to ~\cite{DBLP:conf/tphol/GordonM96} cited above--- equality is postulated as embodying $\alpha$-conversion and a model of the system based on locally nameless syntax has been constructed.

Yet another approach to the formulation of the alpha-structural principles originates in the observation that, if the property to be tried is $\alpha$-compatible ---i.e., it is actually a property of the $\alpha$-classes and not just of the concrete terms--- then induction on the \emph{size} of terms can be used to bridge over the possible gap pointed out above in proofs by induction that confine themselves to convenient choice of bound names. Indeed a step f

 .

\hfill


All the code referred to in this work is compiled in the last Agda's version 2.4.2.2 and 0.9 standard library, and can be accessed at:

\begin{center}
  \href{https://github.com/ernius/formalmetatheory-nominal}{https://github.com/ernius/formalmetatheory-nominal}
\end{center}


\subsection{Related Work}
\label{sec:relatedWork}

There exist several developments in the direction of our work, all of them based the Isabelle/HOL proof assistant. Gordon~\cite{gordon:mechanisation:1993} constructs a similar BVC induction principle over a variation of de Bruijn syntax. The syntax used in Gordons's work was already suggested by de Bruijn~\cite{deBruijn1972381}, in which ``free variables have names but the bound variables are nameless''. In this representation \alp-convertible terms are syntactically equal, but invalid terms appears, so a well-formed predicate is needed to eliminate the incorrect terms. Because this last issue, every introduced function must be proved to be closed under well-formed terms. On the other hand, the main adventage of this mixed strategy is that theorems can be expressed in convetional form, without de Bruijn encoding, and in spite of this, the renaming of bound variables is still supported in proofs, because syntactical equality is up to \alp-conversion. He hide this explicit renaming from proofs introducing an induction principle for decidable predicates, which is proved by induction on the length of terms. As the BVC convention, this induction principle enable us to choose the abstraction variables fresh enough from the context in a similar way as we will do in this work. Although, as Gordon point outs, we belive name-carrying syntax up to literal equality would be needed to represent language definitions, such as that of standard ML, for instance, where syntax is not identified up to \alp-conversion. De Bruijn notation has been used to implement several theorem provers, where syntax is internally represented in De Bruijn but human interacting uses a name-carrying notation. But this is different to use also this internal notation at a logic level. 

Previous approach is \emph{first-order} in the sense that the variable-binding operations of the embedded syntax is distinct form variable-binding at the host proof assistant language. In~\cite{DBLP:conf/tphol/GordonM96}, Gordon and Melham began to explore a \emph{second-order} approach ...




% ~\cite{Norrish04recursivefunction,UN05:formaltreatment,urban08:nominaltechniques,Norrish:mechanisinglambda} 

\subsection{A brief introduction to Agda}

The Agda system~\cite{agdawiki} can be seen both as a programming language with dependent types and as an interactive proof assistant. It implements Martin-Löf's (intentional) type theory~\cite{mlof90} and it extends this theory with a number of features that makes programming more convenient. In order to guarantee logical consistency, only functions that can syntactically be checked total can be defined in the system.

The syntax of Agda resembles that of Haskell and provides many standard programming constructor such as modules, datatypes and case-expressions, signatures and records, and let- and where-expressions. It also allows defining functions by pattern matching on one or several of the function's arguments, and supports a very flexible way of naming expressions and types, including the possibility of having mixfix names (the positions of the arguments in the name are indicated by the character \AgdaSymbol{\_}) and of using Unicode in the names.

Agda supports the possibility of abstracting over the result of an expression when defining a function. This abstraction is performed with the constructor \AgdaKeyword{with}, which effectively adds another argument to the function to be defined that can then be matched in the usual way.

It is possible to omit terms that the type checker can figure out for itself by replacing them by \AgdaSymbol{\_}. Agda also allows the possibility of defining certain arguments as "implicit", which is done by using brackets in the declarations of the arguments. Implicit arguments do not need to be provided, so only arguments that the system can deduce on its own should be defined as implicit. To give an implicit argument explicit one should embrace the corresponding expression with brackets. 



\section{Infrastructure}
\label{sec:infra}

\AgdaTarget{Λ}
\ExecuteMetaData[Term.tex]{term} \hspace{5px}

\ExecuteMetaData[Term.tex]{fresh} \hspace{5px}

\ExecuteMetaData[Atom.tex]{swap} \hspace{5px}

\AgdaTarget{（}
\ExecuteMetaData[Term.tex]{swap} \hspace{5px}

\AgdaTarget{∙ₐ}
\ExecuteMetaData[Permutation.tex]{atomPermutation} \hspace{5px}

\AgdaTarget{∙}
\ExecuteMetaData[Permutation.tex]{permutation} \hspace{5px}

\AgdaTarget{∼α}
\ExecuteMetaData[Alpha.tex]{alpha}

\section{Induction Principles}
\label{sec:induction}

Primitive induction over \AgdaDatatype{Λ} terms.

\AgdaTarget{TermPrimInd}
\begin{figure}[!ht]
  \ExecuteMetaData[TermInduction.tex]{termPrimInduction} 
  \caption{Primitive Induction Principle}
\label{fig:primInd}
\end{figure}

Next term induction principle provides a strong inductive hypothesis for the lambda abstraction case, which gives the property for all permutation of names of the body of the abstraction. This induction principle is proved using the previous introduced principle.

\begin{figure}[!ht]
  \AgdaTarget{TermIndPerm}
  \ExecuteMetaData[TermInduction.tex]{termIndPermutation} 
  \caption{Permutation Induction Principle}
\label{fig:permInd}
\end{figure}

A predicate is \alp-compatible if it holds for a given term it also holds for all \alp-equivalent terms.

\AgdaTarget{αCompatiblePred}
\ExecuteMetaData[Alpha.tex]{alphaCompatible} \hspace{5px}

If a predicate is \alp-compatible then we can prove the following induction principle using previously introduced one. This new principle enables us to choose the variable of the abstraction case different from a given finite list of variables. In this way this principle allow us to emulate Barendregt Variable Convention (BVC), and assume enough fresh variables in a proof, that is, doing proofs over \alp-equivalence classes of terms. Our aim is use this principle whenever is possible, previous and next principles are usefull to internaly deal with swap operation, but we want to hide this operation from our proofs as much as possible.

\AgdaTarget{TermαPrimInd}
\ExecuteMetaData[TermInduction.tex]{alphaPrimInduction} \hspace{5px}

Again assuming an \alp-compatible predicate, and using the second induction principle (figure~\ref{fig:permInd}), we can prove the following induction principle which combines the two previous principles characteristics.

\begin{figure}[!ht]
  \AgdaTarget{TermαIndPerm}
  \ExecuteMetaData[TermInduction.tex]{alphaIndPermutation}
  \caption{Permutation \alp-Induction Principle}
\label{fig:permAlphaInd}
\end{figure}

\section{The Choice Function}

Our recursion principle will proceed by recursion on the structure of terms.
The interesting case is of course that of the \lamb-abstractions, in which the principle ought to satisfy two requirements:

\begin{enumerate}
\item To allow defining the function in question by assuming that the abstraction is \lambAg{\choice}{N} where \choice\ is a name not belonging to a given finite set of names. (This is Barendregt's convention ---in practical cases the set of names to be avoided is determined by a certain predicate but it is always finite.)
\item To equate (i.e. not distinguish) \alphaeqsym-equivalent terms while at the same time avoiding a too coarse identification.
(A principle yielding e.g. only constant functions would indeed identify \alphaeqsym-equivalent terms, but it would be devoid of any interest.)
\end{enumerate}

It would then seem that we need to know the full definition of \alphaeqsym\ in order to implement our recursor. But such is not the case, as what we need in fact is only to determine how to proceed in the case of \lamb-abstractions, whose behavior with respect to \alphaeqsym\ is determined by the simple expedient of ``changing the bound atom''.
So suppose the procedure is receiving an abstraction \lambAg{x}{M}. In order to implement Barendregt's convention, the finite set of names to be avoided has to be provided to the method, which we may represent as a given list $vs$ of atoms. Further, we notice that:
\begin{displaymath}
 \freshin{\chi}{\lambAg{x}{M}} \Rightarrow\  \lambAg{x}{M} \alpeqAg \lambAg{\chi}{\swap{x}{\chi}{M}}
\end{displaymath}
So we obtain an implementation of the required procedure by choosing a name \choice\ such that:\begin{enumerate}
\item $\choice \ninAg vs$
\item \freshin{\chi}{\lambAg{x}{M}} 
\end{enumerate}

and then stating the value of the function which is being defined which corresponds to input \lambAg{\chi}{\swap{x}{\chi}{M}}. For this, the result of the function on  \swap{x}{\chi}{M} can be (recursively) used.
Therefore we are implementing a form of inductive/recursive reasoning on, so to speak, \alphaeqsym-equivalence classes: The value of the function that is being defined for any abstraction is determined as the value of a convenient representative of its \alphaeqsym-equivalence class.
Actually, for the defined correspondence to be indeed a function, it is important that the name \choice\ is chosen in a deterministic way. This can be easily achieved, for instance by determining \choice\ as the \emph{first} name satisfying the requirements above in a fixed enumeration of the type of names, which must of course exist. We implement such determinism coding the following function:

\AgdaTarget{χ}
\ExecuteMetaData[Term.tex]{chi}

This functions has the desired previously enumerated properties. As a consequence of the imposed fresh property, the application of \choiceAg\ function to the same list of variables and \alphaeqsym-equivalent terms should return the same atom, because  \alphaeqsym-equivalent terms have the same fresh atoms.

At this point our development seems to diverge from the nominal one. Our \choiceAg function is reduced to an auxiliary one with the following signature:

\AgdaTarget{χ'}
\ExecuteMetaData[Chi.tex]{chiaux}

\noindent which is not \emph{finite supported}, while nominal theory requires functions to be finitely supported. A function $f : X \rightarrow Y$, where $X,Y$ are nominal sets, is finitely supported if there exists a finite set of atoms $A$\ that for all atoms $a,a' \not\in A$\ and any $x ∈ X$\  $ (a\ \bullet  a') (f ((a\ a') x)) = f (x)$. Back to our choice \choiceAgaux, it can be seen that there no exists such fixed set of atoms such that for any list of atoms in the image, swapping some atoms in it, then applying our choice function, and then again applying the same swapping have no effect in the result. 


\section{Iteration and Recursion Principles}
\label{sec:recursion}

We want to define strong \alp-compatible functions, that is, functions over the \alp-equivalence class of terms. So this functions should not depend on the abstraction variables of a term and return the same result between \alp-equivalent terms. 

\AgdaTarget{strong∼αCompatible}
\ExecuteMetaData[Alpha.tex]{strongAlphaCompatible} \hspace{5px}

We define an iteration principle over raw terms which always produces \alp-compatible functions. This is granted because abstraction variables are given by the induction principle, hidding the specific abstraction variables of the inspected term. In this way the result of a function defined with this iterator has no way to extract any information from abstracted variables. This principle also allow us to give a list of variables from where the abstractions variables will not to be choosen, this will be usefull to define the no capture substitution operation latter. This iteration principle is derived from the last presented induction principle in figure~\ref{fig:permAlphaInd}. 

\AgdaTarget{ΛIt}
\ExecuteMetaData[TermRecursion.tex]{termIteration} \hspace{5px}

Next result make explicit the iterator behaviour in the abstracion case.

\AgdaTarget{ΛItƛ}
\ExecuteMetaData[TermRecursion.tex]{itlambda} \hspace{5px}

The following lemma says our iteration principle always return strong compatibility functions. This result is proved using the induction principle in figure~\ref{fig:permAlphaInd}. 

\begin{figure}[!ht]
  \AgdaTarget{lemmaΛItStrongαCompatible}
  \ExecuteMetaData[TermRecursion.tex]{iterationStrongCompatible}
  \caption{Strong \alp\ Compatibility of the Iteration Principle}
\label{fig:strongAlphaComp}
\end{figure}

From this iteration principle we directly derive the next recursion principle over terms, which also generates strong \alp-compatible functions.

\AgdaTarget{ΛRec}
\ExecuteMetaData[TermRecursion.tex]{termRecursion}

\section{Iterator Application}
\label{sec:itapp}

We present several applications of the iteration/recursive principle defined in previous section. In the following two sub-sections we implement two classic examples of \lamb-calculus theory. In the appendix~\ref{sec:applications} we also apply our iteration/recursion principle to the examples of functions over terms presented in~\cite{Norrish04recursivefunction}. This work presents a sequence of increasing complexity functions,  providinging this way a set of functions to test recursion principles over \lamb-calculus terms. Each of the defined functions respects the \alp-equivalence relation, that is, are strong compatible functions by being implemented over the previously introduced itaration/recursion principles. 

\subsection{Free Variables}
\label{sec:freevar}

We implement the function that returns the free variables of a term.

\ExecuteMetaData[FreeVariables.tex]{freeVariables} \hspace{5px}

As a direct consequence of strong \alp-compatibility of the iteration principle we have that \alp\ compatible terms have equal free variables. 

The relation \AgdaFunction{\_*\_} holds when a variables ocurrs free in a term.

\AgdaTarget{*}
\ExecuteMetaData[Term.tex]{free} \hspace{5px}

We can use the last induction principle (fig.~\ref{fig:permAlphaInd}) to prove the following proposition:

\AgdaTarget{Pfv*}
\ExecuteMetaData[FreeVariables.tex]{fvPred} \hspace{5px}

In the \lamb- abstraction case of the induction proof, we can exclude the variable $a$\ from the abstraction variables of the term where the induction is done, simplifying this proof. We have to prove that $\forall b \neqAg a, a \inAg \fv (\lambAg{b}{M}) \Rightarrow a \free \lambAg{b} {M}$, knowing by inductive hypothesis that $\forall \pi , a \inAg \fv (\pi \perm M) \Rightarrow a \free (\pi \perm M)$. Using the lemma \AgdaFunction{ΛItƛ}, about the behaviour of the iterator for the abstraction case, we know $\fv (\lambAg{b}{M}) = \fv ((b \perm \chi)\ M) - \chi$\ where $\chi = \choiceAg [\,]\ \lambAg{b}{M}$, so we can infer that $a \inAg \fv ((b \perm \chi)\ M)$\ and $a \neqAg \chi$. We can use the inductive hypothesis with $\pi = [(b , \chi)]$\ and previous result to obtain that $a \free ((b \perm \chi) \perm M)$, which  using that $b \neqAg a$\ and $a \neqAg \chi$ we can obtain that $a \free M$. Finlally, we are able to apply the constructor \AgdaInductiveConstructor{ƛ*} of the relation \free\ to previous result and $b \neqAg a$\ to obtain the desired result.

%So $a \inAg \fv (\lambAg{b}{M})$\ and $b \neqAg a$ then we can derive that $a \inAg \fv M$ holds. Now,  instantiating the inductive hypothesis with an empty permtutation and the previous result, we have that $a \free M$,  using again that $b \neqAg a$, we can then conclude the desired result: $a \free \lambAg{b}{M}$.

The flexibility to exclude variable $a$\  comes with an extra cost, we need to prove that the predicate $\forall a , \AgdaFunction{Pfv*} a$\ is \alp-compatible in order to use the choosen induction principle. This \alp-compatible proof is direct once we prove that \free\ is an \alp-compatible relation and the \fv function is strong \alp-compatible. The last property is direct because we implemented \fv with the iteration principle, so the extra cost is just the proof that \free\ is \alp-compatible.

Another approach where the last proof can be automatically obtained, as we freely obtainded that \fv is strong \alp-complatible, is to define the free relation using our iteration principle, and not a data type as previously done.

\AgdaTarget{free}
\ExecuteMetaData[FreeVariables.tex]{free} \hspace{5px}

For the variable case we return the type of the propositional equality, inhabited only if the searched variable is equal to the term variable. The application case is the disjoint union of the types returned by the recursive calls, that is, the union of the variable free ocurrence evidence in the applied terms. Finally, in the abstraction case we can choose the abstraction variable to be different from the searchead one, so we can ignore the abstraction variable, and return just the recursive call, containing the evidence of any variable free ocurrence in the abstraction body. 

This free predicate impementation is strong compatible by construction because we build it from our iterator principle, so given any variable $a$\ and two \alp-compatible terms $M,N$, the returned set should be the same. So is direct that if the predicate holds for $M$ (which means that the returned set is inhabited for $M$), then the predicate should also hold for $N$. 

From this point we can  do an analog proof of \AgdaFunction{Pfv*} proposition, but now using this new free predicate definition which is \alp-compatible by construction. This give us a framework where we can define strong compatible functions and also \alp-compatible predicates over terms, and then prove properties about theses functions and predicates using our induction principle that provides us with the BVC.

\subsection{Substitution}
\label{subst}

We implement the no capture substitution operation, we avoid any variable capture giving as variables to not to choose from as variable abtractions: the substituted variable and the free variables of the replaced term.

\ExecuteMetaData[Substitution.tex]{substitution} \hspace{5px}

Again because of the strong \alp-compability of the iteration principle we obtain the following result for free:

\AgdaTarget{lemmaSubst1}
\ExecuteMetaData[Substitution.tex]{lemmaSubst1} \hspace{5px}

Using the induction principle in figure~\ref{fig:permInd} we prove:

\AgdaTarget{lemmaSubst2}
\ExecuteMetaData[Substitution.tex]{lemmaSubst2} \hspace{5px}

From the two previous result we directly obtain next \alp-compatibility substitution lemma .

\AgdaTarget{lemmaSubst}
\ExecuteMetaData[Substitution.tex]{lemmaSubst} \hspace{5px}

With previous result we can derive that our substitution operation is \alp-equivalent with a naive one for fresh enough abstraction variables.

\AgdaTarget{lemmaƛ∼[]}
\ExecuteMetaData[Substitution.tex]{naivesubstitution} \hspace{5px}

We can combine this last result with the \AgdaFunction{TermαPrimInd} principle which emulates BVC convention, and mimic in this way a pen and pencil inductive proofs over \alp-equivalence classes of terms about substitution operation. As an example we show next substitution composition predicate:

\AgdaTarget{PSC}
\ExecuteMetaData[Substitution.tex]{Psubstcomp} \hspace{5px}

Next we give a direct equational proof that \AgdaFunction{PSC} predicate is \alp-compatible:

\AgdaTarget{αCompatiblePSC}
\ExecuteMetaData[Substitution.tex]{PsubstcompAlphaCompatible} \hspace{5px}

For the interesting abstraction case of the \alp-structural induction over the lambda term, we asume the abstraction variables in the term are not in the substituted variables nor the subsituted terms. In this way the substitution operations are \alp-compatible to naive substitutions, then the inductive hipothesis allow us to complete the the inductive proof in a direct maner. Next we show the code fragment correspondint to this proof:
 
\ExecuteMetaData[Substitution.tex]{abstractionComposition} \hspace{5px}

Remarkably theses results are directly derived from the first primitive induction principle, and no need of induction on the length of terms or accesible predicates were needed in all of this formalization.

\appendix

\section{Iteration/Recursion Applications}
\label{sec:applications}

In the following sections we successfully apply our iteration/recursion principle to all the examples from~\cite{Norrish04recursivefunction}. This work presents a sequence of increasing complexity functions definitions to provide a test for any principle of function definition, where each of the given functions respects the \alp-equivalence relation.

\subsection{Case Analysis and Examining Constructor Arguments}
\label{sec:caseanalysis}

The following family of functions distinguishes between constructors returning the constructor components, giving in a sense a kind of \emph{pattern-matching}.

\begin{minipage}{.5\textwidth}
\[\begin{array}{rll}
isVar &: \Lambda \rightarrow& Maybe\ ( Variable ) \\
isVar &(v\ x)         &= Just \\
isVar &(M \cdot N)   &= Nothing \\
isVar &(\lambda x M) &= Nothing
\end{array}\]
\end{minipage}
\begin{minipage}{.5\textwidth}
\[\begin{array}{rll}
isApp &: \Lambda \rightarrow& Maybe\ (\Lambda \times \Lambda) \\
isApp &(v\ x)          &= Nothing \\
isApp &(M \cdot N)   &= Just (M , N) \\
isApp &(\lambda x M) &= Nothing
\end{array}\]
\end{minipage}

\centerline{
\begin{minipage}{.5\textwidth}
\[
\begin{array}{rll}
isAbs &: \Lambda \rightarrow& Maybe\ (Variable \times \Lambda) \\
isAbs &(v\ x)         &= Nothing \\
isAbs &(M \cdot N)   &= Nothing \\
isAbs &(\lambda x M) &= Just (x , M)
\end{array} \]
\end{minipage}}

Next we present the corresponding codifications using our iteration/recursion principle:

\AgdaTarget{isVar} \AgdaTarget{isApp} \AgdaTarget{isAbs}
\ExecuteMetaData[Norrish.tex]{constructors} \hspace{5px}

\subsection{Simple recursion}
\label{sec:rec}

The size function returns a numeric measurement of the size of a term.

\centerline{
\begin{minipage}{.5\textwidth}
\[
\begin{array}{rll}
size &: \Lambda \rightarrow& \mathbb{N} \\
size &(v\ x)         &= 1 \\
size &(M \cdot N)   &= size (M) + size (N) + 1 \\
size &(\lambda x M) &= size (M) + 1 
\end{array} \]
\end{minipage}}

\AgdaTarget{size}
\ExecuteMetaData[Norrish.tex]{size} \hspace{5px}

\subsection{Alfa Equality}

Next functions decides the \alp-equality relation between two terms.

\AgdaTarget{equal}
\ExecuteMetaData[Norrish.tex]{alphaEqual} \hspace{5px}

Observe that \AgdaFunction{isAbs} function also normalises N, so it is correct in last line to ask if the two binders are equal.

\subsection{Recursion Mentioning a Bound Variable}
\label{sec:recbound}

The $enf$ function is true of a term if it is in $\eta$-normal form, the $fv$ function returns the set of a term’s free variables and was previously defined.

\centerline{
\begin{minipage}{.8\textwidth}
\[
\begin{array}{rll}
enf &: \Lambda \rightarrow& Bool \\
enf &(v\ x)         &= True \\
enf &(M \cdot N)   &= enf (M) \wedge enf (N) + 1 \\
enf &(\lambda x M) &= enf (M) \wedge (∃ N, x / isApp (M) == Just (N , v\ x) \Rightarrow x \in fv (N))
\end{array} \]
\end{minipage}}

\hspace{5px}

\AgdaTarget{enf}
\ExecuteMetaData[Norrish.tex]{enf} \hspace{5px}

\subsection{Recursion with an Additional Parameter}

Given the ternary type of possible directions to follow when passing through a term $({Lt, Rt, In})$, corresponding to the two sub-terms of an application constructor and the body of an abstraction, return the set of paths (lists of directions) to the occurrences of the given free variable in a term, where $cons$\ insert an element in front of a list.

\[
\begin{array}{rrll}
&vposns &: Variable \times \Lambda \rightarrow & List\ (List\ Direction) \\
&vposns &(x , v\ y)         &= if\ (x == y)\ then\ [[]]\ else\ []   \\
&vposns &(x , M \cdot N)    &= map\ (cons\ Lt)\ (vposns\ x\ M) +\!\!+  \\
& & &\ \ \ map\ (cons\ Rt)\ (vposns\ x\ N) \\
x \neq y \Rightarrow&vposns &(x ,\lambda y M)   &= map\ (cons\ In)\ (vposns\ x\ M) \\
\end{array} \]

Notice how the condition guard of the abstraction case is translated to the list of variables from where not to chose from the abstraction variable.

\AgdaTarget{vposns}
\ExecuteMetaData[Norrish.tex]{vposns} \hspace{5px}

\subsection{Recursion with Varying Parameters and Terms as Range}

A variant of the substitution function, which substitutes a term for a variable, but further adjusts the term being substituted by wrapping it in one application of the variable named "0" per traversed binder.

\[
\begin{array}{rrll}
&sub' &: \Lambda \times Variable \times  \Lambda &   \rightarrow  \Lambda  \\
&sub' &(P , x , v\ y)         &= if\ (x == y)\ then\ P\ else\ (v\ y)   \\
&sub' &(P , x , M \cdot N)    &= (sub' (P , x , M)) \cdot (sub' (P , x , N)) \\
\left. 
\begin{array}{c}
y \neq x  \ \wedge \\
 y \neq 0\ \  \wedge \\
 y \not\in fv(P) \\
\end{array} \right\} \Rightarrow&sub' &(P , x , \lambda y M)   &= \lambda y (sub' ((v\ 0) \cdot M , x , M)) \\
\end{array} \]

To implement this function with our iterator principle we must change the parameters order, so our iterator principle now returns a function that is waiting the term to be substituted. In this way we manage to vary the parameter through the iteration.

\AgdaTarget{sub'}
\ExecuteMetaData[Norrish.tex]{sub} \hspace{5px}

\bibliographystyle{plain}% the recommended bibstyle
\bibliography{resumen}

\end{document}